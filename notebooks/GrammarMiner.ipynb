{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Mining Input Grammars\n",
    "\n",
    "So far, the grammars we have seen have been mostly specified manually – that is, you (or the person knowing the input format) had to design and write a grammar in the first place.  While the grammars we have seen so far have been rather simple, creating a grammar for complex inputs can involve quite some effort.  In this chapter, we therefore introduce techniques that automatically _mine_ grammars from programs – by executing the programs and observing how they process which parts of the input.  In conjunction with a grammar fuzzer, this allows us to (1) take a program, (2) extract its input grammar, and (3) fuzz it with high efficiency and effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Prerequisites**\n",
    "\n",
    "* You should have read the [chapter on grammars](Grammars.ipynb).\n",
    "* The [chapter on configuration fuzzing](ConfigurationFuzzer.ipynb) introduces grammar mining for configuration options, as well as observing variables and values during execution.\n",
    "* The concept of parsing from [chapter on parsers](Parser.ipynb) is also useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the `process_inventory()`  method from the [chapter on parsers](Parser.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fuzzingbook_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Parser import process_inventory, process_vehicle, process_car, process_van, lr_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes inputs of the following form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INVENTORY = \"\"\"\\\n",
    "1997,van,Ford,E350\n",
    "2000,car,Mercury,Cougar\n",
    "1999,car,Chevy,Venture\\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(process_inventory(INVENTORY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found from the [chapter on parsers](Parser.ipynb) that coarse grammars do not work well for fuzzing when the input format includes details expressed only in code. That is, even though we have the formal specification of CSV files ([RFC 4180](https://tools.ietf.org/html/rfc4180)), the inventory system includes further rules as to what is expected at each index of the CSV file. The solution of simply recombining existing inputs, while practical, is incomplete. In particular, it relies on a formal input specification being available in the first place. However, we have no assurance that the program obeys the input specification given.\n",
    "\n",
    "One of the ways out of this predicament is to interrogate the program under test as to what its input specification is. That is, if the program under test is written in a recursive descent style, with specific methods responsible for handling specific parts of the input, one can recover the parse tree, by observing the process of parsing. Further, one can recover a reasonable approximation of the grammar by abstraction from multiple input trees.\n",
    "\n",
    " _We start with the assumption (1) that the program is written in such a fashion that specific methods are responsible for parsing specific fragments of the program -- This includes almost all ad hoc parsers._\n",
    "\n",
    "The idea is as follows\n",
    "* We hook into the Python execution and observe how the input fragments are produced and named in different methods.\n",
    "* Stitch the input fragments together in a tree structure to produce a parse tree.\n",
    "* Abstract common elements from multiple parse trees to produce the Context Free Grammar of the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## A Simple Grammar Miner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we want to obtain the input grammar for the function `process_vehicle()`. We first collect the sample inputs for this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEHICLES = INVENTORY.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen from the chapter on [configuration fuzzing](ConfigurationFuzzer.ipynb) that one can hook into the Python runtime to observe the arguments to a function and any local variables created. We have also seen that one can obtain the context of execution by inspecting the `frame` argument. Here is a simple tracer that can return the local variables and other contextual information in a traced function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traceit(frame, event, arg):\n",
    "    method_name = frame.f_code.co_name\n",
    "    if method_name != \"process_vehicle\":\n",
    "        return\n",
    "    file_name = frame.f_code.co_filename\n",
    "    param_names = [frame.f_code.co_varnames[i] for i in range(frame.f_code.co_argcount)]\n",
    "    print(event, file_name, method_name, param_names, frame.f_locals)\n",
    "    return traceit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first obtain and save the current trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldtrace = sys.gettrace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, set our trace function as the current one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.settrace(traceit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, run the code under this trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_vehicle(VEHICLES[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we reset the trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.settrace(oldtrace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the interests of modularity, we expand the `traceit()` function to a full fledged class `Tracer` that acts as a *context manager*. A context manager in Python requires two methods `__enter__()` to enter the context and `__exit__()` to leave the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracer:\n",
    "    def __enter__(self):\n",
    "        self.oldtrace = sys.gettrace()\n",
    "        sys.settrace(self.trace_event)\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        sys.settrace(self.oldtrace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logic in the `traceit()` function is now moved to a method `trace_event()` which is set as the trace function by the `Tracer` context manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracer(Tracer):\n",
    "    def trace_event(self, frame, event, arg):\n",
    "        method_name = frame.f_code.co_name\n",
    "        if method_name != \"process_vehicle\":\n",
    "            return\n",
    "        file_name = frame.f_code.co_filename\n",
    "        param_names = [\n",
    "            frame.f_code.co_varnames[i]\n",
    "            for i in range(frame.f_code.co_argcount)\n",
    "        ]\n",
    "        print(event, file_name, method_name, param_names, frame.f_locals)\n",
    "        return self.trace_event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " That is, any function executed under it gets a tracing hook installed, and after the execution, the hook is uninstalled automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Tracer() as tracer:\n",
    "    process_vehicle(VEHICLES[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `trace_event()` relies on information from the `frame` variable which exposes Python internals. We define a `context` class that encapsulates the information that we need from the `frame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Context` class provides easy access to the information such as the current module, and parameter names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Context:\n",
    "    def __init__(self, frame, track_caller=True):\n",
    "        self.method = self._method(frame)\n",
    "        self.parameter_names = self._get_parameter_names(frame)\n",
    "        self.file_name = self._file_name(frame)\n",
    "        self.parent = Context(frame.f_back,\n",
    "                              False) if track_caller and frame.f_back else None\n",
    "\n",
    "    def _get_parameter_names(self, frame):\n",
    "        return [\n",
    "            frame.f_code.co_varnames[i]\n",
    "            for i in range(frame.f_code.co_argcount)\n",
    "        ]\n",
    "\n",
    "    def _file_name(self, frame):\n",
    "        return frame.f_code.co_filename\n",
    "\n",
    "    def _method(self, frame):\n",
    "        return frame.f_code.co_name\n",
    "\n",
    "    def extract_vars(self, frame):\n",
    "        return frame.f_locals\n",
    "\n",
    "    def parameters(self, all_vars):\n",
    "        return {k: v for k, v in all_vars if k in self.parameter_names}\n",
    "\n",
    "    def qualified(self, all_vars):\n",
    "        return {\"%s:%s\" % (self.method, k): v for k, v in all_vars}\n",
    "\n",
    "    def _t(self):\n",
    "        return (self.file_name, self.method, ','.join(self.parameter_names))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"%s:%s(%s)\" % self._t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how the context can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traceit(frame, event, arg):\n",
    "    cxt = Context(frame)\n",
    "    print((cxt.method, cxt.parameter_names, (cxt.parent.method, cxt.parent.parameter_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldtrace = sys.gettrace()\n",
    "sys.settrace(traceit)\n",
    "process_vehicle(VEHICLES[0])\n",
    "sys.settrace(oldtrace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trace produced by executing any function can get overwhelmingly large. Hence, we need restrict our attention to specific modules. Further, we also restrict our attention exclusively to `str` variables since these variables are more likely to contain input fragments. (We will show how to deal with complex objects later.)\n",
    "\n",
    "We use the `context` to decide which modules to monitor, and which variables to trace.\n",
    "\n",
    "We store the current *input string* so that it can be used to determine if any particular string fragments came from the current input string. We add a `kwargs` for optional arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracer(Tracer):\n",
    "    def __init__(self, my_input, **kwargs):\n",
    "        self.my_input, self.trace = my_input, []\n",
    "        self.options(kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, the only optional argument is `files` which we use to indicate the specific source files we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracer(Tracer):\n",
    "    def options(self, kwargs):\n",
    "        self.files = kwargs.get('files') or []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `files` is checked to determine if a particular event should be traced or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracer(Tracer):\n",
    "    def tracing_context(self, ctx, event, arg):\n",
    "        if not self.files:\n",
    "            return True\n",
    "        return any(ctx.file_name.endswith(f) for f in self.files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the context of events, we also want to restrict our attention to specific variables. For now, we want to focus only on strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracer(Tracer):\n",
    "    def tracing_var(self, k, v):\n",
    "        return isinstance(v, str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We modify the `trace_event()` to call an `on_event()` function with the context information only on the specific events we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracer(Tracer):\n",
    "    def on_event(self, event, arg, cxt, my_vars):\n",
    "        self.trace.append((event, arg, cxt, my_vars))\n",
    "\n",
    "    def trace_event(self, frame, event, arg):\n",
    "        cxt = Context(frame)\n",
    "        if not self.tracing_context(cxt, event, arg):\n",
    "            return self.trace_event\n",
    "\n",
    "        my_vars = [(k, v) for k, v in cxt.extract_vars(frame).items()\n",
    "                   if self.tracing_var(k, v)]\n",
    "        self.on_event(event, arg, cxt, my_vars)\n",
    "        return self.trace_event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Tracer` class can now focus on specific kinds of events on specific files. Further, it provides a first level filter for variables that we find interesting. For example, we want to focus specifically on `string` variables that contain input fragments. Here is how our updated `Tracer` can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Tracer(VEHICLES[0]) as tracer:\n",
    "    process_vehicle(VEHICLES[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The execution produced the following trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tracer.trace:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are saving the input already in Tracer, it is redundant to specify it separately again as an argument. We modify our tracer to supply the saved argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracer(Tracer):\n",
    "    def __call__(self):\n",
    "        return self.my_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this change, the `Tracer` can be used as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Tracer(VEHICLES[0]) as tracer:\n",
    "    process_vehicle(tracer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `settrace()` function hooks into the Python debugging facility. When it is in operation, no debugger can hook into the program. Hence, we limit the tracer to the simplest implementation possible as given above, and implement the core of grammar mining in later stages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a `Tracker` class that processes the trace from the `Tracer`.\n",
    "\n",
    "The tracker identifies string fragments that are part of the input string, and stores them in a dictionary `my_assignments`. It saves the trace, and the corresponding input for processing. Finally it calls `process()` to process the `trace` it was given. We additionally define a logging facility for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker:\n",
    "    def __init__(self, my_input, trace, **kwargs):\n",
    "        self.my_assignments = {}\n",
    "        self.trace = trace\n",
    "        self.my_input = my_input\n",
    "        self.options(kwargs)\n",
    "        self.process()\n",
    "\n",
    "    def options(self, kwargs):\n",
    "        self.log = kwargs.get('log') or False\n",
    "\n",
    "    def logger(self, var):\n",
    "        self.log and print(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our tracer simply records the variable values as they occur. We next need to check if the variables contain values from the **input string**. Common ways to do this is to rely on symbolic execution or at least dynamic tainting, which are powerful, but also complex. However, one can obtain a reasonable approximation by simply relying on substring search. That is, we consider any value produced that is a substring of the original input string to have come from the original input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the problems of using substring search is that short string sequences tend to be included in other string sequences even though they may not have come from the original string. That is, say the input fragment is `v`. It could have equally come from either `van` or `chevy`. We rely on being able to predict the exact place input where a given fragment occurred. Hence, we define a constant `FRAGMENT_LEN` such that we ignore strings up to that length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAGMENT_LEN=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For longer strings, we rely on string inclusion to detect if the string came from the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker(Tracker):\n",
    "    def include(self, var, value):\n",
    "        return len(value) > FRAGMENT_LEN and value in self.my_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tracker processes each event, and at each event, it updates the dictionary `my_assignments` with the current local variables that contain strings that are part of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker(Tracker):\n",
    "    def track_event(self, event, arg, cxt, my_vars):\n",
    "        self.my_assignments.update({k: v for k, v in my_vars if self.include(k, v)})\n",
    "\n",
    "    def process(self):\n",
    "        for event, arg, cxt, my_vars in self.trace:\n",
    "            self.track_event(event, arg, cxt, my_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the tracker, we can obtain the input fragments as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = Tracker(tracer.my_input, tracer.trace)\n",
    "for k,v in tracker.my_assignments.items():\n",
    "    print(k, '=', repr(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mining a Derivation Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input fragments from the `Tracker` only tell half the story. The fragments may be created at different stages of parsing. Hence, we need to assemble the fragments to a  derivation tree of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Grammars import START_SYMBOL, syntax_diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivation tree `Miner` is initialized with the input string, and the variable assignments, and it converts the assignments to the corresponding derivation tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Miner:\n",
    "    def __init__(self, my_input, my_assignments, **kwargs):\n",
    "        self.my_input = my_input\n",
    "        self.my_assignments = my_assignments\n",
    "        self.options(kwargs)\n",
    "        self.tree = self.get_derivation_tree()\n",
    "\n",
    "    def options(self, kwargs):\n",
    "        self.log = kwargs.get('log') or False\n",
    "\n",
    "    def logger(self, indent, var):\n",
    "        self.log and print('\\t' * indent, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea is as follows:\n",
    "* We represent the derivation tree as a [straight line grammar](https://en.wikipedia.org/wiki/Straight-line_grammar) with each node represented by a key value pair. The key corresponds to the variable name, and the value corresponds to the representation of the value of the variable. The value representation may contain references to other nodes.\n",
    "* We start with a derivation tree with a single node -- the start symbol and the input string as its leaf.\n",
    "* For each pair _VAR_, _VALUE_ found in `my_assignments`:\n",
    "\n",
    "1. We search for occurrences of _VALUE_ in the grammar\n",
    "2. We replace them by <_VAR_>\n",
    "3. We add a new rule <_VAR_> $\\rightarrow$ <_VALUE_> to the grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a wrapper to generate a nonterminal from a variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_nonterminal(var):\n",
    "    return \"<\" + var.lower() + \">\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main miner is as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Miner(Miner):\n",
    "    def get_derivation_tree(self):\n",
    "        tree = {START_SYMBOL: (self.my_input, )}\n",
    "        my_assignments = self.my_assignments.copy()\n",
    "\n",
    "        while True:\n",
    "            new_rules = []\n",
    "            for var, value in my_assignments.items():\n",
    "                self.logger(0, \"%s = %s\" % (var, value))\n",
    "                for key, repl in tree.items():\n",
    "                    self.logger(1, \"%s : %s\" % (key, repl))\n",
    "                    if not any(value in t for t in repl):\n",
    "                        continue\n",
    "                    alt_key = to_nonterminal(var)\n",
    "                    new_arr = []\n",
    "                    for k, token in enumerate(repl):\n",
    "                        if not value in token:\n",
    "                            new_arr.append(token)\n",
    "                        else:\n",
    "                            arr = token.split(value)\n",
    "                            new_arr.extend(\n",
    "                                list(sum(zip(arr,\n",
    "                                             len(arr) * [alt_key]), ()))[:-1])\n",
    "                    tree[key] = tuple(i for i in new_arr if i)\n",
    "                    new_rules.append((var, alt_key, value))\n",
    "\n",
    "            if not new_rules:\n",
    "                break  # Nothing to expand anymore\n",
    "\n",
    "            for (var, alt_key, value) in new_rules:\n",
    "                tree[alt_key] = (value, )\n",
    "                self.logger(0, \"+%s = %s\" % (alt_key, value))\n",
    "\n",
    "                # Do not expand this again\n",
    "                del my_assignments[var]\n",
    "\n",
    "        return {key: values for key, values in tree.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Miner` is used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Tracer(VEHICLES[0]) as tracer:\n",
    "    process_inventory(tracer())\n",
    "assignments = Tracker(tracer.my_input, tracer.trace).my_assignments\n",
    "dt = Miner(tracer.my_input, assignments, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the grammar representation to a parse tree is accomplished by the `to_tree()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Miner(Miner):\n",
    "    def to_tree(self, key=START_SYMBOL):\n",
    "        if key not in self.tree:\n",
    "            return (key, [])\n",
    "        children = [self.to_tree(c) for c in self.tree[key]]\n",
    "        return (key, children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Miner(tracer.my_input, assignments).to_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining all the pieces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trees = []\n",
    "for VEHICLE in VEHICLES:\n",
    "    print(VEHICLE)\n",
    "    with Tracer(VEHICLE) as tracer:\n",
    "        process_inventory(tracer())\n",
    "    assignments = Tracker(tracer.my_input, tracer.trace).my_assignments\n",
    "    trees.append((tracer.my_input, assignments))\n",
    "    for var, val in assignments.items():\n",
    "        print(var + \" = \" + repr(val))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the method `display_tree()` to view the parse tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GrammarFuzzer import GrammarFuzzer, FasterGrammarFuzzer, display_tree, tree_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dt = []\n",
    "for inputstr, assignments in trees:\n",
    "    print(inputstr)\n",
    "    dt = Miner(inputstr, assignments)\n",
    "    csv_dt.append(dt)\n",
    "    display_tree(dt.to_tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Recovering Grammar from Derivation Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a class `Infer` that can combine multiple derivation trees to produce the grammar. The initial grammar is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Infer:\n",
    "    def __init__(self):\n",
    "        self.grammar = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `add_tree()` method gets a combined list of non-terminals from current grammar, and the tree to be added to the grammar, and updates the definitions of each non-terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Infer(Infer):\n",
    "    def add_tree(self, t):\n",
    "        merged_grammar = {}\n",
    "        for key in list(self.grammar.keys()) + list(t.tree.keys()):\n",
    "            alternates = set(self.grammar.get(key, []))\n",
    "            if key in t.tree:\n",
    "                alternates.add(''.join(t.tree[key]))\n",
    "            merged_grammar[key] = list(alternates)\n",
    "        self.grammar = merged_grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Infer` is used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Infer()\n",
    "for dt in csv_dt:\n",
    "    i.add_tree(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax_diagram(i.grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given execution traces from various inputs, one can define `recover_grammar()` to obtain the complete grammar from the traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_grammar(traces):\n",
    "    m = Infer()\n",
    "    for inputstr, trace in traces:\n",
    "        dt = Miner(inputstr, Tracker(inputstr, trace).my_assignments)\n",
    "        m.add_tree(dt)\n",
    "    return m.grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1. Recovering the Inventory Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "for inputstr in VEHICLES:\n",
    "    with Tracer(inputstr) as tracer:\n",
    "        process_vehicle(tracer())\n",
    "    traces.append((tracer.my_input, tracer.trace))\n",
    "inventory_grammar = recover_grammar(traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2. Recovering URL Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our algorithm is robust enough to recover grammar from real world programs. For example, the `urlparse` function in the Python `urlib` module accepts the following sample URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLS = [\n",
    "    'http://user:pass@www.google.com:80/?q=path#ref',\n",
    "    'https://www.cispa.saarland:80/',\n",
    "    'http://www.fuzzingbook.org/#News',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The urllib caches its intermediate results for faster access. Hence, we need to disable it using `clear_cache()` after every invocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, clear_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the sample URLs to recover grammar as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "for inputstr in URLS:\n",
    "    clear_cache()\n",
    "    with Tracer(inputstr, files=['urllib/parse.py']) as tracer:\n",
    "        urlparse(tracer())\n",
    "    traces.append((tracer.my_input, tracer.trace))\n",
    "url_grammar = recover_grammar(traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recovered grammar describes the URL format reasonably well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax_diagram(url_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use our recovered grammar for fuzzing as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = GrammarFuzzer(inventory_grammar)\n",
    "for i in range(10):\n",
    "    print(f.fuzz())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recovered grammar can be used for fuzzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = GrammarFuzzer(url_grammar)\n",
    "for i in range(10):\n",
    "    print(f.fuzz())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with the Simple Miner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the problems with our simple grammar miner is the assumption that variables have unique names. Unfortunately, that may not hold true in all cases. For example, here is a URL with a slightly different format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLS_X = URLS + ['ftp://freebsd.org/releases/5.8']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grammar generated from this set of samples is not as nice as what we got earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "for inputstr in URLS_X:\n",
    "    clear_cache()\n",
    "    with Tracer(inputstr, files=['urllib/parse.py']) as tracer:\n",
    "        urlparse(tracer())\n",
    "    traces.append((tracer.my_input, tracer.trace))\n",
    "grammar = recover_grammar(traces)\n",
    "syntax_diagram(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To investigate why the `url` and `scheme` definitions have gone wrong, let us inspect the trace for the newly added URL and a previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "with Tracer(URLS_X[0], log=True) as tracer:\n",
    "    urlparse(tracer())\n",
    "for i, t in enumerate(tracer.trace):\n",
    "    if t[0] in {'call', 'line'} and 'parse.py' in str(t[2]) and t[3]:\n",
    "        print(i, t[2]._t()[1], t[3:])\n",
    "print()\n",
    "clear_cache()\n",
    "with Tracer(URLS_X[-1], log=True) as tracer:\n",
    "    urlparse(tracer())\n",
    "for i, t in enumerate(tracer.trace):\n",
    "    if t[0] in {'call', 'line'} and 'parse.py' in str(t[2]) and t[3]:\n",
    "        print(i, t[2]._t()[1], t[3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the value of `url` changes in `urlparse` and `urlsplit`? In `URLS[0]`, the value of `url` at `Line:60` is `/` which is ignored as its length is less than `FRAGMENT_LEN`. For these, the value of `url` used is the value from `Line:59`. On the other hand for `URLS_X[-1]`, the corresponding value of `url` at `Line:87` is `/releases/5.8` which is sufficient to overcome the `FRAGMENT_LEN` restriction.\n",
    "\n",
    "Is there a way to relax the `FRAGMENT_LEN` restriction? One way to do it is to restrict the amount of data we look at. If we can limit the variables inspected for inclusion to only those variables that are in context, and secondly, only those variables that have been assigned before, it might succeed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar Miner with Reassignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also proxy the variable dictionary so that it will only update if it does not already contain a value. For that, we define a new class `Vars` which represents our variables. The base input is associated with the start symbol. We also save the activation record in `istack`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vars:\n",
    "    def __init__(self, stack):\n",
    "        self.defs = {START_SYMBOL: stack.original}\n",
    "        self.istack = stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary needs two methods: `update()` that takes a set of key-value pairs to update itself, and `set_kv()` that updates a particular key-value pair if the value does not already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vars(Vars):\n",
    "    def set_kv(self, k, v):\n",
    "        if k not in self.defs:\n",
    "            self.defs[k] = v\n",
    "\n",
    "    def update(self, v):\n",
    "        for k,v in v.items():\n",
    "            self.set_kv(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReassignedVars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the class `ReassignedVars`. This keeps track of all variable reassignments in `accessed_seq_var`. Further, the `value_register` keeps track of the previous variables that contained a particular string fragment. Finally, the variable definitions in `defs` is augmented with an extra item that indicates which method this variable was defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReassignedVars(Vars):\n",
    "    def __init__(self, original):\n",
    "        self.accessed_seq_var = {}\n",
    "        self.value_register = {}\n",
    "        self.defs = {START_SYMBOL: original}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables are only allowed to replace fragments of other variables in the current context. For this, we need to know what context (i.e the method instance) we are in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the variable registry. Specifically, we try to detect when a particular variable has been reassigned by monitoring the values taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReassignedVars(ReassignedVars):\n",
    "    def var_init(self, var):\n",
    "        if var not in self.accessed_seq_var:\n",
    "            self.accessed_seq_var[var] = 0\n",
    "\n",
    "    def var_assign(self, var):\n",
    "        self.accessed_seq_var[var] += 1\n",
    "\n",
    "    def var_name(self, var):\n",
    "        return \"%s[%d]\" % (var, self.accessed_seq_var[var])\n",
    "\n",
    "    def set_kv(self, var, val):\n",
    "        self.var_init(var)\n",
    "        sa_var = self.var_name(var)\n",
    "        if sa_var not in self.defs:\n",
    "            self.defs[sa_var] = val\n",
    "            self.value_register[val] = self.value_register.get(val) or set()\n",
    "            self.value_register[val].add(sa_var)\n",
    "        else:  # possible reassignment\n",
    "            my_vars = self.value_register.get(val)\n",
    "            if my_vars is None or sa_var not in my_vars:  # a change in value\n",
    "                self.var_assign(var)\n",
    "                sa_var = self.var_name(var)\n",
    "                self.defs[sa_var] = val\n",
    "                self.value_register[val] = self.value_register.get(\n",
    "                    val) or set()\n",
    "                self.value_register[val].add(sa_var)\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AssignTracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `AssignTracker` improves upon the `StackTracker` by keeping track of a method stack, and a count of the number of times a particular method has been invoked. This allows us to specify a particular method invocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssignTracker(Tracker):\n",
    "    def __init__(self, my_input, trace, **kwargs):\n",
    "        self.my_input = my_input\n",
    "        self.my_assignments = ReassignedVars(my_input)\n",
    "        \n",
    "        self.trace = trace\n",
    "        self.options(kwargs)\n",
    "        self.process()\n",
    "\n",
    "    def options(self, kwargs):\n",
    "        self.track_params = kwargs.get('track_params') or True\n",
    "        self.track_vars = kwargs.get('track_vars') or True\n",
    "        self.track_return = kwargs.get('track_return') or False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the trio of methods `on_call()`, `on_line()` and `on_return()`. The main difference is the new `call_enter()` and `call_exit()` methods for registering the current method invocation, and the accessible scope given by `scope()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssignTracker(AssignTracker):\n",
    "    def selected(self, variables):\n",
    "        return {k: v for k, v in variables if self.include(k, v)}\n",
    "\n",
    "    def on_call(self, arg, cxt, my_vars):\n",
    "        if not self.track_params:\n",
    "            return\n",
    "        my_parameters = {k: v for k, v in cxt.parameters(my_vars).items()}\n",
    "        self.my_assignments.update(self.selected(my_parameters.items()))\n",
    "\n",
    "    def on_line(self, arg, cxt, my_vars):\n",
    "        if not self.track_vars:\n",
    "            return\n",
    "        my_vars = self.selected(my_vars)\n",
    "        if not self.track_params:\n",
    "            for k in cxt.parameter_names:\n",
    "                my_vars.pop(k, None)\n",
    "        self.my_assignments.update(my_vars)\n",
    "\n",
    "    def on_return(self, arg, cxt, my_vars):\n",
    "        self.on_line(arg, cxt, my_vars)\n",
    "        if not self.track_return:\n",
    "            return\n",
    "        var = '(<-%s)' % cxt.method\n",
    "        self.my_assignments.update(self.selected([(var, arg)]))\n",
    "\n",
    "    def track_event(self, event, arg, cxt, my_vars):\n",
    "        if event == 'call':\n",
    "            return self.on_call(arg, cxt, my_vars)\n",
    "\n",
    "        if event == 'return':\n",
    "            return self.on_return(arg, cxt, my_vars)\n",
    "\n",
    "        if event == 'exception':\n",
    "            return\n",
    "\n",
    "        self.on_line(arg, cxt, my_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `call_enter()` and `call_exit()` functions are used to register the method invocation and correctly set the current method being executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "traces = []\n",
    "for inputstr in URLS_X:\n",
    "    clear_cache()\n",
    "    with Tracer(inputstr, files=['urllib/parse.py']) as tracer:\n",
    "        urlparse(tracer())\n",
    "    traces.append((tracer.my_input, tracer.trace))\n",
    "    \n",
    "    tracker = AssignTracker(tracer.my_input, tracer.trace)\n",
    "    for k,v in tracker.my_assignments.defs.items():\n",
    "        print(k, '=', repr(v))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Miner(Miner):\n",
    "    def get_derivation_tree(self):\n",
    "        my_assignments = self.my_assignments.copy()\n",
    "        tree = {}\n",
    "        for var, value in my_assignments.items():\n",
    "            nt_var = var if var == START_SYMBOL else to_nonterminal(var)\n",
    "            self.logger(0, \"%s = %s\" % (nt_var, value))\n",
    "            if tree:\n",
    "                append = False\n",
    "                for key, repl in tree.items():\n",
    "                    self.logger(1, \"%s : %s\" % (key, repl))\n",
    "                    if not any(value in t for t in repl):\n",
    "                        continue\n",
    "                    new_arr = []\n",
    "                    for k, token in enumerate(repl):\n",
    "                        if not value in token:\n",
    "                            new_arr.append(token)\n",
    "                        else:\n",
    "                            append = True\n",
    "                            arr = token.split(value)\n",
    "                            new_arr.extend(\n",
    "                                list(sum(zip(arr,\n",
    "                                             len(arr) * [nt_var]), ()))[:-1])\n",
    "                    tree[key] = tuple(i for i in new_arr if i)\n",
    "                if append:\n",
    "                    self.logger(0, \"+%s = %s\" % (nt_var, value))\n",
    "                    tree[nt_var] = set([value])\n",
    "            else:\n",
    "                tree[nt_var] = (value, )\n",
    "        return  {key: values for key, values in tree.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_grammar(traces):\n",
    "    m = Infer()\n",
    "    for inputstr, trace in traces:\n",
    "        st = AssignTracker(inputstr, trace)\n",
    "        dt = Miner(inputstr, st.my_assignments.defs)\n",
    "        m.add_tree(dt)\n",
    "    return m.grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: Recovering Inventory Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "for inputstr in VEHICLES:\n",
    "    with Tracer(inputstr) as tracer:\n",
    "        process_vehicle(tracer())\n",
    "    traces.append((tracer.my_input, tracer.trace))\n",
    "grammar = recover_grammar(traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "syntax_diagram(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "for inputstr in URLS_X:\n",
    "    print(inputstr)\n",
    "    clear_cache()\n",
    "    with Tracer(inputstr, files=['urllib/parse.py']) as tracer:\n",
    "        urlparse(tracer())\n",
    "    traces.append((tracer.my_input, tracer.trace))\n",
    "grammar = recover_grammar(traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax_diagram(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: Recovering URL Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we obtain the derivation tree of the URL 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### URL 1 derivation tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "with Tracer(URLS_X[0], files=['urllib/parse.py']) as tracer:\n",
    "    urlparse(tracer())\n",
    "sm = AssignTracker(tracer.my_input, tracer.trace)\n",
    "dt = Miner(tracer.my_input, sm.my_assignments.defs)\n",
    "display_tree(dt.to_tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we obtain the derivation tree of URL 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### URL 4 derivation tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "with Tracer(URLS_X[-1], files=['urllib/parse.py']) as tracer:\n",
    "    urlparse(tracer())\n",
    "sm = AssignTracker(tracer.my_input, tracer.trace)\n",
    "dt = Miner(tracer.my_input, sm.my_assignments.defs)\n",
    "display_tree(dt.to_tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivation trees seem to belong to the same grammar. Hence, we obtain the grammar for the complete set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "traces = []\n",
    "for inputstr in URLS_X:\n",
    "    clear_cache()\n",
    "    with Tracer(inputstr, files=['urllib/parse.py']) as tracer:\n",
    "        urlparse(tracer())\n",
    "    traces.append((tracer.my_input, tracer.trace))\n",
    "grammar = recover_grammar(traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar Miner with Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to relax the `FRAGMENT_LEN`, we incorporate inspection of the variables in the current context. For that, we define a class `InputStack` which holds the unmodified record of activation of the method. Essentially, we start with the original input at the base of the stack, and for each new method call we push the parameters of that call into the stack as a new record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputStack:\n",
    "    def __init__(self, i):\n",
    "        self.original = i\n",
    "        self.inputs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to check if a particular variable be saved, we define `in_current_record()` which checks only the last activation record for inclusion (rather than the original input string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputStack(InputStack):\n",
    "    def in_current_record(self, val):\n",
    "        return any(val in var for var in self.inputs[-1].values()) if self.inputs else val in self.original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we can relax the FRAGMENT_LEN restriction, we can not do away with it completely. We only look at variables that are at least 2 characters long. We define the method `ignored()` that returns true if either the variable is not a string, or the variable length is less than 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputStack(InputStack):\n",
    "    def ignored(self, val):\n",
    "        return not (isinstance(val, str) and len(val) > 1) # FRAGMENT_LEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define the `include()` method that checks whether the variable needs to be ignored, and if it is not to be ignored, whether the variable value is present in the activation record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputStack(InputStack):\n",
    "    def include(self, k, val):\n",
    "        if self.ignored(val):\n",
    "            return False\n",
    "        return self.in_current_record(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define `push()` that pushes relevant variables in the current context to the activation record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputStack(InputStack):\n",
    "    def push(self, inputs):\n",
    "        my_inputs = {k: v for k, v in inputs.items() if self.include(k, v)}\n",
    "        self.inputs.append(my_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a method returns, we also need a corresponding `pop()` to unwind the activation record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputStack(InputStack):\n",
    "    def pop(self):\n",
    "        return self.inputs.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a convenience method `height()` that returns the height of the current activation record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputStack(InputStack):\n",
    "    def height(self):\n",
    "        return len(self.inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack Tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `InputStack` and `Vars` defined, we can now define the `StackTracker`. The `StackTracker` only saves variables if the value is present in the current activation record. To fine-tune the process, we define three optional parameters:\n",
    "* `track_params` -- if false, do not save any of the parameters in the variable dictionary\n",
    "* `track_vars` -- if false, only consider `call` and `return` events, ignoring `line`\n",
    "* `track_return` -- if true, add a virtual variable to the Vars representing the return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackTracker(Tracker):\n",
    "    def __init__(self, my_input, trace, **kwargs):\n",
    "        self.istack = InputStack(my_input)\n",
    "        self.my_assignments = Vars(self.istack)\n",
    "        self.trace = trace\n",
    "        self.options(kwargs)\n",
    "        self.process()\n",
    "\n",
    "    def options(self, kwargs):\n",
    "        self.track_params = kwargs.get('track_params') or True\n",
    "        self.track_vars = kwargs.get('track_vars') or True\n",
    "        self.track_return = kwargs.get('track_return') or False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a wrapper for checking whether a variable is present in the activation record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackTracker(StackTracker):\n",
    "    def include(self, var, value):\n",
    "        return self.istack.include(var, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define methods `on_call`, `on_line` and `on_return` that is responsible for processing of corresponding events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackTracker(StackTracker):\n",
    "    def on_call(self, arg, cxt, my_vars):\n",
    "        my_parameters = {\n",
    "            k: v\n",
    "            for k, v in cxt.parameters(my_vars).items()\n",
    "            if not self.istack.ignored(v)\n",
    "        }\n",
    "        self.istack.push(my_parameters)\n",
    "        if self.track_params:\n",
    "            self.my_assignments.update(my_parameters)\n",
    "\n",
    "    def on_line(self, arg, cxt, my_vars):\n",
    "        if self.track_vars:\n",
    "            qvars = {\"%s:%s\" % (cxt.method, k): v for k, v in my_vars}\n",
    "            my_vars = {\n",
    "                var: value\n",
    "                for var, value in qvars.items() if self.include(var, value)\n",
    "            }\n",
    "            if not self.track_params:\n",
    "                my_vars = {\n",
    "                    var: value\n",
    "                    for var, value in my_vars.items()\n",
    "                    if var not in cxt.parameter_names\n",
    "                }\n",
    "            self.my_assignments.update(my_vars)\n",
    "\n",
    "    def on_return(self, arg, cxt, my_vars):\n",
    "        self.istack.pop()\n",
    "        self.on_line(arg, cxt, my_vars)\n",
    "        if self.track_return:\n",
    "            var = '(<-%s)' % cxt.method\n",
    "            if self.include(var, arg):\n",
    "                self.my_assignments.update({var: arg})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These methods are called from `track_event()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackTracker(StackTracker):\n",
    "    def track_event(self, event, arg, cxt, my_vars):\n",
    "        if event == 'call':\n",
    "            return self.on_call(arg, cxt, my_vars)\n",
    "\n",
    "        if event == 'return':\n",
    "            return self.on_return(arg, cxt, my_vars)\n",
    "\n",
    "        if event == 'exception':\n",
    "            return\n",
    "\n",
    "        self.on_line(arg, cxt, my_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `StackTracker` as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_traces = []\n",
    "for inputstr in VEHICLES:\n",
    "    clear_cache()\n",
    "    with Tracer(inputstr) as tracer:\n",
    "        urlparse(tracer())\n",
    "    sm = StackTracker(tracer.my_input, tracer.trace)\n",
    "    url_traces.append((tracer.my_input, sm))\n",
    "    for k,v in sm.my_assignments.defs.items():\n",
    "        print(k, v)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mining a Derivation Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned earlier, while mining the derivation tree, we only look at variable assignments that happened *before* the current variable assignment took place. Note that we still assume that a particular variable is only assigned once. The algorithm is as follows\n",
    "\n",
    "For each (VAR, VALUE) found:\n",
    "* We search for occurrences of VALUE in the grammar\n",
    "* We replace them by VAR\n",
    "* We add a new rule VAR -> VALUE to the grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Miner(Miner):\n",
    "    def get_derivation_tree(self):\n",
    "        my_assignments = self.my_assignments.copy()\n",
    "        tree = {}\n",
    "        for var, value in my_assignments.items():\n",
    "            nt_var = var if var == START_SYMBOL else to_nonterminal(var)\n",
    "            self.logger(0, \"%s = %s\" % (nt_var, value))\n",
    "            if tree:\n",
    "                append = False\n",
    "                for key, repl in tree.items():\n",
    "                    self.logger(1, \"%s : %s\" % (key, repl))\n",
    "                    if not any(value in t for t in repl):\n",
    "                        continue\n",
    "                    new_arr = []\n",
    "                    for k, token in enumerate(repl):\n",
    "                        if not value in token:\n",
    "                            new_arr.append(token)\n",
    "                        else:\n",
    "                            append = True\n",
    "                            arr = token.split(value)\n",
    "                            new_arr.extend(\n",
    "                                list(sum(zip(arr,\n",
    "                                             len(arr) * [nt_var]), ()))[:-1])\n",
    "                    tree[key] = tuple(i for i in new_arr if i)\n",
    "                if append:\n",
    "                    self.logger(0, \"+%s = %s\" % (nt_var, value))\n",
    "                    tree[nt_var] = set([value])\n",
    "            else:\n",
    "                tree[nt_var] = (value, )\n",
    "        return  {key: values for key, values in tree.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_grammar(traces):\n",
    "    m = Infer()\n",
    "    for inputstr, trace in traces:\n",
    "        st = StackTracker(inputstr, trace)\n",
    "        dt = Miner(inputstr, st.my_assignments.defs)\n",
    "        m.add_tree(dt)\n",
    "    return m.grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: Recovering Inventory Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "for inputstr in VEHICLES:\n",
    "    with Tracer(inputstr) as tracer:\n",
    "        process_vehicle(tracer())\n",
    "    traces.append((tracer.my_input, tracer.trace))\n",
    "grammar = recover_grammar(traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax_diagram(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: Recovering URL Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we obtain the derivation tree of the URL 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### URL 1 derivation tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "with Tracer(URLS_X[0], files=['urllib/parse.py']) as tracer:\n",
    "    urlparse(tracer())\n",
    "sm = StackTracker(tracer.my_input, tracer.trace)\n",
    "dt = Miner(tracer.my_input, sm.my_assignments.defs)\n",
    "display_tree(dt.to_tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we obtain the derivation tree of URL 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### URL 4 derivation tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "with Tracer(URLS_X[-1], files=['urllib/parse.py']) as tracer:\n",
    "    urlparse(tracer())\n",
    "sm = StackTracker(tracer.my_input, tracer.trace)\n",
    "dt = Miner(tracer.my_input, sm.my_assignments.defs)\n",
    "display_tree(dt.to_tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivation trees seem to belong to the same grammar. Hence, we obtain the grammar for the complete set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "for inputstr in URLS_X:\n",
    "    clear_cache()\n",
    "    with Tracer(inputstr, files=['urllib/parse.py']) as tracer:\n",
    "        urlparse(tracer())\n",
    "    traces.append((tracer.my_input, tracer.trace))\n",
    "grammar = recover_grammar(traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax_diagram(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recovered grammar seems to have avoided the pitfall we discussed previously in the simple miner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with the Stack Miner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned previously, our algorithm for mining grammars does not yet account for variable reassignments. The current `StackMiner` has problems when variables are reassigned which can happen due to loops or recursive calls. An example is as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Tracer(INVENTORY) as tracer:\n",
    "    process_inventory(tracer())\n",
    "sm = StackTracker(tracer.my_input, tracer.trace)\n",
    "for k,v in sm.my_assignments.defs.items():\n",
    "    print(k,' = ',v)\n",
    "dt = Miner(tracer.my_input, sm.my_assignments.defs)\n",
    "display_tree(dt.to_tree(), graph_attr=lr_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the derivation tree obtained is not quite what we expected. We consider how to resolve this problem next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar Miner with Re-Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to deal with variable reassignments, we need to modify our variable dictionary to be aware of reassignments. Further, we also include further restriction on the Grammar Miner with Stack that only the variables currently in scope are inspected for fragments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AssignMiner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major difference in the `AssignMiner` is how we account for the new `scope` annotation in assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssignMiner(Miner):\n",
    "    def get_derivation_tree(self):\n",
    "        my_assignments = self.my_assignments.copy()\n",
    "        tree = {}\n",
    "        for var, value_ in my_assignments.items():\n",
    "            nt_var = var if var == START_SYMBOL else to_nonterminal(var)\n",
    "            value, scope_of_var = value_\n",
    "            self.logger(0, \"%s = %s\" % (nt_var, value))\n",
    "            if tree:\n",
    "                append = False\n",
    "                for key, repl in tree.items():\n",
    "                    self.logger(1, \"%s : %s\" % (key, repl))\n",
    "                    if not any(value in t for t in repl):\n",
    "                        continue\n",
    "                    if scope_of_var != ':0' and scope_of_var not in key:\n",
    "                        continue\n",
    "                    new_arr = []\n",
    "                    for k, token in enumerate(repl):\n",
    "                        if not value in token:\n",
    "                            new_arr.append(token)\n",
    "                        else:\n",
    "                            append = True\n",
    "                            arr = token.split(value)\n",
    "                            new_arr.extend(\n",
    "                                list(sum(zip(arr,\n",
    "                                             len(arr) * [nt_var]), ()))[:-1])\n",
    "                    tree[key] = tuple(i for i in new_arr if i)\n",
    "                if append:\n",
    "                    self.logger(0, \"+%s = %s\" % (nt_var, value))\n",
    "                    tree[nt_var] = set([value])\n",
    "            else:\n",
    "                tree[nt_var] = (value, )\n",
    "        return {key: values for key, values in tree.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssignMiner(AssignMiner):\n",
    "    def to_tree(self, key=START_SYMBOL):\n",
    "        def simplify(var):\n",
    "            return re.sub(r'\\[.+\\]', '', var)\n",
    "\n",
    "        if key not in self.tree:\n",
    "            return (simplify(key), [])\n",
    "        children = [self.to_tree(c) for c in self.tree[key]]\n",
    "        return (simplify(key), children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with Tracer(INVENTORY) as tracer:\n",
    "    process_inventory(tracer())\n",
    "sm = AssignTracker(tracer.my_input, tracer.trace)\n",
    "dt = AssignMiner(tracer.my_input, sm.my_assignments.defs)\n",
    "display_tree(dt.to_tree(), graph_attr=lr_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Lessons Learned\n",
    "\n",
    "* Given a set of inputs, we can learn an input grammar by examining variable values during execution.\n",
    "* The resulting grammars can be used right during fuzzing.\n",
    "* TODO: make the point that our initial implementation is about learning regular grammar not CFG because we do not know how to handle mutually recursive and looping procedures\n",
    "* TODO: Use process_vehicle as a pervading example.\n",
    "* TODO: Mention that control flow dependencies is not tracked in dynamic taints. But it is tracked in simple miner with string inclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "_Link to subsequent chapters (notebooks) here, as in:_\n",
    "\n",
    "* [use _mutations_ on existing inputs to get more valid inputs](MutationFuzzer.ipynb)\n",
    "* [use _grammars_ (i.e., a specification of the input format) to get even more valid inputs](Grammars.ipynb)\n",
    "* [reduce _failing inputs_ for efficient debugging](Reducer.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "\\cite{Lin2008}\n",
    "\\cite{Hoschele2017}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercises\n",
    "\n",
    "_Close the chapter with a few exercises such that people have things to do.  To make the solutions hidden (to be revealed by the user), have them start with_\n",
    "\n",
    "```markdown\n",
    "**Solution.**\n",
    "```\n",
    "\n",
    "_Your solution can then extend up to the next title (i.e., any markdown cell starting with `#`)._\n",
    "\n",
    "_Running `make metadata` will automatically add metadata to the cells such that the cells will be hidden by default, and can be uncovered by the user.  The button will be introduced above the solution._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Exercise 1: Flattening complex objects\n",
    "\n",
    "Our grammar miners only check for string fragments. However, programs may often pass containers or custom objects containing input fragments. Can you modify our grammar miner to correctly account for the complex objects too?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Here is a possible solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "**Solution.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "def flatten(key, val):\n",
    "    # Should we limit flatened objects to repr ~ tstr here or during call?\n",
    "    tv = type(val)\n",
    "    if isinstance(val, (int, float, complex, str, bytes, bytearray)):\n",
    "        return [(key, val)]\n",
    "    elif isinstance(val, (set, frozenset, list, tuple, range)):\n",
    "        values = [e for i, elt in enumerate(val) for e in flatten(i, elt)]\n",
    "        return [(\"%s.%d\" % (key, i), v) for i, v in values]\n",
    "    elif isinstance(val, dict):\n",
    "        values = [e for k, elt in val.items() for e in flatten(k, elt)]\n",
    "        return [(\"%s.%s\" % (key, k), v) for k, v in values]\n",
    "    elif isinstance(val, tstr):\n",
    "        return [(key, val)]\n",
    "    elif hasattr(val,'__dict__'):\n",
    "        values = [e for k, elt in val.__dict__.items() for e in flatten(k, elt)]\n",
    "        return [(\"%s.%s\" % (key, k), v) for k, v in values]\n",
    "    else:\n",
    "        return [(key, repr(v))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "_Some more text for the solution_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "solution": "hidden",
    "solution2": "hidden",
    "solution2_first": true,
    "solution_first": true
   },
   "source": [
    "### Exercise 2: _Title_\n",
    "\n",
    "_Text of the exercise_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "solution": "hidden",
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** _Solution for the exercise_"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.2",
    "jupytext_version": "0.8.6"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "374.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
